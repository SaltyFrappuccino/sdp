import re
import logging
from core.utils import send_message

# –ö—ç—à –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞, —á—Ç–æ–±—ã –Ω–µ —á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∫–∞–∂–¥—ã–π —Ä–∞–∑
_handbook_data = None
HANDBOOK_FILE_PATH = '../frontend/src/panels/Handbook.tsx'

def parse_handbook_tsx(file_path: str):
    """
    –ü–∞—Ä—Å–∏—Ç TSX —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π 'sections'.
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        logging.error(f"–§–∞–π–ª —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {file_path}")
        return None

    match = re.search(r'const sections = (\[[\s\S]*?\]);', content, re.DOTALL)
    if not match:
        logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –º–∞—Å—Å–∏–≤ 'sections' –≤ —Ñ–∞–π–ª–µ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞.")
        return None
    
    js_array_string = match.group(1)
    sections_data = []
    section_objects_str = re.split(r'(?<=}),\s*(?={)', js_array_string.strip('[]\n'))

    for obj_str in section_objects_str:
        if not obj_str.strip():
            continue
            
        section = {}
        id_match = re.search(r"id:\s*'(.*?)'", obj_str)
        title_match = re.search(r"title:\s*'(.*?)'", obj_str)
        category_match = re.search(r"category:\s*'(.*?)'", obj_str)
        content_match = re.search(r'content:\s*\{([\s\S]*)\}', obj_str, re.DOTALL)

        if id_match: section['id'] = id_match.group(1)
        if title_match: section['title'] = title_match.group(1)
        if category_match: section['category'] = category_match.group(1)

        if content_match:
            content_str = content_match.group(1)
            content = {}
            c_title_match = re.search(r"title:\s*'(.*?)'", content_str)
            c_desc_match = re.search(r"description:\s*'(.*?)'", content_str)
            
            kp_match = re.search(r'keyPoints:\s*\[([^\]]*)\]', content_str, re.DOTALL)
            if kp_match:
                points_str = kp_match.group(1)
                points = [p.strip().strip("'\"") for p in points_str.split(',') if p.strip()]
                content['keyPoints'] = points
            
            dc_match = re.search(r'detailedContent:\s*`([\s\S]*)`', content_str, re.DOTALL)
            if dc_match:
                content['detailedContent'] = dc_match.group(1).strip()

            if c_title_match: content['title'] = c_title_match.group(1)
            if c_desc_match: content['description'] = c_desc_match.group(1)
            section['content'] = content

        if all(k in section for k in ['id', 'title', 'content']):
             sections_data.append(section)

    return sections_data

def get_handbook_data():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞, –∏—Å–ø–æ–ª—å–∑—É—è –∫—ç—à."""
    global _handbook_data
    if _handbook_data is None:
        _handbook_data = parse_handbook_tsx(HANDBOOK_FILE_PATH)
    return _handbook_data

def parse_detailed_content(text: str) -> dict:
    """–ü–∞—Ä—Å–∏—Ç –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –ø–æ–¥—Å–µ–∫—Ü–∏–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º '###'."""
    subsections = {}
    chunks = re.split(r'\n### ', text)
    if len(chunks) < 2:
        return {}

    for chunk in chunks[1:]:
        lines = chunk.split('\n')
        title = lines[0].strip()
        content = '\n'.join(lines[1:]).strip()
        subsections[title] = content
    return subsections

def search_in_handbook(query: str):
    """
    –ò—â–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —Å–µ–∫—Ü–∏—é (–∏ –ø–æ–¥—Å–µ–∫—Ü–∏—é) –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (—Å–µ–∫—Ü–∏—è, –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫, –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ–¥—Å–µ–∫—Ü–∏–∏) –∏–ª–∏ (None, None, None).
    """
    data = get_handbook_data()
    if not data:
        return None, None, None

    query_words = set(re.findall(r'\w+', query.lower()))
    best_section_score = 0
    best_section = None

    # –≠—Ç–∞–ø 1: –ù–∞–π—Ç–∏ –ª—É—á—à—É—é –°–ï–ö–¶–ò–Æ
    for section in data:
        score = 0
        content = section.get('content', {})
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ (–≤–µ—Å 10)
        title_words = set(re.findall(r'\w+', section.get('title', '').lower()))
        score += 10 * len(query_words.intersection(title_words))
        content_title_words = set(re.findall(r'\w+', content.get('title', '').lower()))
        score += 10 * len(query_words.intersection(content_title_words))

        # –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã (–≤–µ—Å 7)
        key_points_text = ' '.join(content.get('keyPoints', [])).lower()
        key_points_words = set(re.findall(r'\w+', key_points_text))
        score += 7 * len(query_words.intersection(key_points_words))

        # –û–ø–∏—Å–∞–Ω–∏–µ (–≤–µ—Å 3)
        desc_words = set(re.findall(r'\w+', content.get('description', '').lower()))
        score += 3 * len(query_words.intersection(desc_words))

        # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç (–≤–µ—Å 1 –∑–∞ —Å–ª–æ–≤–æ, 15 –∑–∞ —Ñ—Ä–∞–∑—É)
        detailed_text = content.get('detailedContent', '').lower()
        if query.lower() in detailed_text:
            score += 15
        detailed_words = set(re.findall(r'\w+', detailed_text))
        score += 1 * len(query_words.intersection(detailed_words))

        if score > best_section_score:
            best_section_score = score
            best_section = section

    # –≠—Ç–∞–ø 2: –ï—Å–ª–∏ —Å–µ–∫—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞, –∏—â–µ–º –ª—É—á—à—É—é –ü–û–î–°–ï–ö–¶–ò–Æ –≤–Ω—É—Ç—Ä–∏ –Ω–µ–µ
    if best_section and best_section_score > 4:
        content = best_section.get('content', {})
        detailed_content_text = content.get('detailedContent')

        if detailed_content_text:
            subsections = parse_detailed_content(detailed_content_text)
            best_subsection_score = 0
            best_subsection_title = None
            best_subsection_content = None

            for sub_title, sub_content in subsections.items():
                sub_score = 0
                # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –≤–µ—Å –∑–∞ –ø—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                if query.lower() in sub_title.lower():
                    sub_score += 50
                
                sub_title_words = set(re.findall(r'\w+', sub_title.lower()))
                sub_score += 20 * len(query_words.intersection(sub_title_words))

                if sub_score > best_subsection_score:
                    best_subsection_score = sub_score
                    best_subsection_title = sub_title
                    best_subsection_content = sub_content
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â—É—é –ø–æ–¥—Å–µ–∫—Ü–∏—é, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–µ
            if best_subsection_score > 20:
                return best_section, best_subsection_title, best_subsection_content

        # –ï—Å–ª–∏ –ø–æ–¥—Å–µ–∫—Ü–∏—é –Ω–µ –Ω–∞—à–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å–µ–∫—Ü–∏—é
        return best_section, None, None

    return None, None, None

def format_section_for_vk(section, subsection_title=None, subsection_content=None):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—É—é —Å–µ–∫—Ü–∏—é (–∏–ª–∏ –ø–æ–¥—Å–µ–∫—Ü–∏—é) –≤ –∫—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è VK."""
    
    if subsection_title and subsection_content:
        message = f"üìò –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫: {subsection_title}\n\n"
        
        first_paragraph = subsection_content.split('\n\n')[0]
        summary = first_paragraph.strip()

        if len(summary) > 500:
            end_pos = summary.rfind('.', 0, 500)
            summary = summary[:end_pos + 1] if end_pos != -1 else summary[:500] + '...'

        summary = re.sub(r'####\s*', 'üî∏ ', summary)
        summary = re.sub(r'[\*_]', '', summary)
        summary = re.sub(r'-\s', 'üîπ ', summary)
        
        message += summary
        message += f"\n\n(–ù–∞–π–¥–µ–Ω–æ –≤ —Ä–∞–∑–¥–µ–ª–µ: ¬´{section.get('title', 'N/A')}¬ª)"
        return message

    content = section.get('content', {})
    title = content.get('title', section.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'))
    description = content.get('description', '')
    key_points = content.get('keyPoints', [])

    message = f"üìò –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫: {title}\n\n"
    if description:
        message += f"‚ñ™ {description}\n\n"

    if key_points:
        message += "–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:\n"
        for point in key_points[:7]:
            message += f"üîπ {point}\n"
    
    message += f"\n(–ù–∞–π–¥–µ–Ω–æ –≤ —Ä–∞–∑–¥–µ–ª–µ: ¬´{section.get('title', 'N/A')}¬ª)"
    return message

def handbook_command(vk, event, args):
    """–ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ."""
    query = " ".join(args).strip()
    if not query:
        send_message(vk, event.peer_id, "üìù –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ –Ω–∞–π—Ç–∏ –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ.")
        return
        
    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ–Ω–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
    if get_handbook_data() is None:
        send_message(vk, event.peer_id, "‚è≥ –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫, –∏–Ω–¥–µ–∫—Å–∏—Ä—É—é —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.")
    
    # –ü–æ–∏—Å–∫
    result_section, sub_title, sub_content = search_in_handbook(query)
    
    if result_section:
        result_message = format_section_for_vk(result_section, sub_title, sub_content)
    else:
        result_message = f"‚ÑπÔ∏è –ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É ¬´{query}¬ª –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞."

    send_message(vk, event.peer_id, result_message)
